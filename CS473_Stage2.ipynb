{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"fr0btXuUs23k","executionInfo":{"status":"ok","timestamp":1733420727411,"user_tz":300,"elapsed":20932,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb28429d-6bec-47c0-ec38-1f8c31d08cc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Cell\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["# Imports\n","import matplotlib.pyplot as plt\n","import re\n","import pandas as pd\n","import numpy as np\n","import sys\n","import os\n","import csv\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import string\n","from nltk.stem import PorterStemmer\n","import gensim\n","from gensim import corpora\n","from gensim.utils import simple_preprocess\n","from gensim.models import TfidfModel\n","from gensim.similarities import MatrixSimilarity\n","from nltk.stem import WordNetLemmatizer as wnl\n","import sys\n","import random"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BKxNqexsx6a","executionInfo":{"status":"ok","timestamp":1733420743813,"user_tz":300,"elapsed":16403,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"788ba26a-9253-4b86-ebd0-c929b66a67c7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/cs478ModelTraining/Collection 3\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dF-nwf77q9Rn","executionInfo":{"status":"ok","timestamp":1733420744549,"user_tz":300,"elapsed":739,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"71b30e52-a7ec-4170-dffe-abb99bdb2179"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset1\tgradescope_method1.csv\t\tgradescope_method3_tuned.csv\n","Dataset2\tgradescope_method2_doc2vec.csv\tstage_2_final_method3.csv\n","ERD_grades.csv\tgradescope_method2_sbert.csv\tstage2_grading_method1.csv\n"]}]},{"cell_type":"markdown","source":["# GENERAL VARIABLES AND FUNCTIONS"],"metadata":{"id":"fEQYcXrDBHTR"}},{"cell_type":"markdown","source":["# YOU MAY HAVE TO CHANGE THESE PATHS DEPENDING ON WHERE THEY EXIST IN YOUR GOOGLE DRIVE"],"metadata":{"id":"IgjGE4ZuKvGZ"}},{"cell_type":"code","source":["# Important directory paths\n","question1_directory_path = \"/content/drive/MyDrive/cs478ModelTraining/Collection 3/Dataset1\"\n","question2_directory_path = \"/content/drive/MyDrive/cs478ModelTraining/Collection 3/Dataset2\""],"metadata":{"id":"TvHP-wwt1Kxq","executionInfo":{"status":"ok","timestamp":1733420744549,"user_tz":300,"elapsed":4,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def getERDGradesAndListOfSubmissionFiles():\n","\n","  # get dictionary of the grades (ground truth values) --> ERD # with mapping to its grade\n","  graded_ERDs_CSV = pd.read_csv(\"/content/drive/MyDrive/cs478ModelTraining/Collection 3/ERD_grades.csv\", sep='\\t')\n","  graded_ERDS_dict = {\n","      row['ERD_No']: (row['dataset1_grade'], row['dataset2_grade'])\n","      for index, row in graded_ERDs_CSV.iterrows()\n","  }\n","  graded_ERDS_dict = dict(sorted(graded_ERDS_dict.items()))\n","  # 1-103 are graded, 104 - 136 are ungraded, doesn't exist --> 62, 89, 113, 120, 126 --> total 131\n","\n","  # get list of text files with objects + text from OD/OCR\n","  question1_list_of_files =  []\n","  for filename in os.listdir(question1_directory_path ):\n","      if filename.endswith('.txt'):\n","          question1_list_of_files.append(filename)\n","\n","  question2_list_of_files =  []\n","  for filename in os.listdir(question2_directory_path ):\n","      if filename.endswith('.txt'):\n","          question2_list_of_files.append(filename)\n","\n","  return graded_ERDS_dict, question1_list_of_files, question2_list_of_files"],"metadata":{"id":"x5dpgOgHrhOm","executionInfo":{"status":"ok","timestamp":1733420744549,"user_tz":300,"elapsed":3,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# METHOD 1 CODE"],"metadata":{"id":"O0kkK7VJBPAW"}},{"cell_type":"code","source":["def preprocess_all_student_submissions_per_question(question_number, question1_list_of_files, question2_list_of_files):\n","\n","  question_directory_path = \"\"\n","  question_list_of_files = []\n","  if question_number == 1:\n","    question_list_of_files = question1_list_of_files\n","    question_directory_path = question1_directory_path\n","  else:\n","    question_list_of_files = question2_list_of_files\n","    question_directory_path = question2_directory_path\n","\n","  final_erd_dict = {}\n","\n","  stop_words = set(stopwords.words('english'))\n","\n","  for erd in question_list_of_files:\n","\n","    file_path = question_directory_path + \"/\" + erd\n","    list_of_erd_words = []\n","    with open(file_path, 'r') as file:\n","      lines = file.readlines()\n","\n","      # Process each line by stripping newline characters\n","      lines = [line.strip(\"\\n\") for line in lines]\n","\n","      # change all letters to lower case\n","      lines = [line.lower() for line in lines]\n","\n","      for line in lines:\n","\n","        # REMOVE RELATION and IDENT REL NAMES CODE\n","        if ((line[2:5] == 'rel' and line[5] == \"'\") or (line[2:11] == 'ident_rel' and line[11] == \"'\")):\n","            if (line[2:11] == 'ident_rel'):\n","              list_of_erd_words.append(\"ident_rel\")\n","            else:\n","              list_of_erd_words.append(\"rel\")\n","            continue\n","\n","        word_tokens = word_tokenize(line)\n","\n","        i = 1\n","        word_prefix = \"\"\n","\n","        for word in word_tokens:\n","          if (word not in string.punctuation and word not in stop_words):\n","\n","            word = word.strip(string.punctuation)\n","\n","            # PREFIX CODE:\n","            if (i == 1):\n","              # if it is the first one of the line (object name), just append it, and save the object name\n","              word_prefix = word\n","              list_of_erd_words.append(word)\n","              continue\n","            else:\n","              # if the word (non object name) contains hyphens or underscores\n","              if (\"_\" in word or \"-\" in word):\n","                  # split them into individual words\n","                  split_words = re.split(r\"[_\\-]\", word)\n","                  for split_word in split_words:\n","                    # add the prefix to each of the split words\n","                    list_of_erd_words.append(word_prefix + \"_\" + split_word)\n","              else:\n","                word_to_add = word_prefix + \"_\" + word\n","                list_of_erd_words.append(word_to_add)\n","\n","          i = i + 1\n","\n","    erd_number = int(erd.split('.')[0])\n","\n","    # LEMMATIZATION CODE\n","    list_of_erd_words = [wnl().lemmatize(w) for w in list_of_erd_words]\n","\n","    final_erd_dict[erd_number] = list_of_erd_words\n","\n","  return final_erd_dict\n"],"metadata":{"id":"mLiYV92CtZeF","executionInfo":{"status":"ok","timestamp":1733424872085,"user_tz":300,"elapsed":122,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def build_tf_idf_vectors(graded_erd_dictionary, ungraded_erd_dictionary):\n","\n","  # create a combined dictionary of the graded submissions AND ungraded\n","  list_of_graded_ERDs = list(graded_erd_dictionary.values())\n","  list_of_ungraded_ERDs = list(ungraded_erd_dictionary.values())\n","\n","  combined_erds = list_of_graded_ERDs + list_of_ungraded_ERDs\n","  combined_dictionary = corpora.Dictionary(combined_erds)\n","\n","  # create BoW representation for graded and ungraded submissions separately\n","  BoW_corpus_graded_ERDs = [combined_dictionary.doc2bow(doc, allow_update=True) for doc in list_of_graded_ERDs]\n","  BoW_corpus_ungraded_ERDs = [combined_dictionary.doc2bow(doc, allow_update=True) for doc in list_of_ungraded_ERDs]\n","\n","  # create TF-IDF models for both graded submissions and ungraded submissions\n","  tfidf_graded_ERDs = TfidfModel(BoW_corpus_graded_ERDs, smartirs='lnc')\n","  tfidf_ungraded_ERDs = TfidfModel(BoW_corpus_ungraded_ERDs, smartirs='lnc')\n","\n","  # Convert both to their TF-IDF representation\n","  corpus_tfidf_graded_ERDs = tfidf_graded_ERDs[BoW_corpus_graded_ERDs]\n","  corpus_tfidf_ungraded_ERDs = tfidf_ungraded_ERDs[BoW_corpus_ungraded_ERDs]\n","\n","  # Create similiarty index using TF-IDF representation of graded submission\n","  similarity_index_graded_ERDs = MatrixSimilarity(corpus_tfidf_graded_ERDs, num_features=len(combined_dictionary))\n","\n","  return corpus_tfidf_graded_ERDs, corpus_tfidf_ungraded_ERDs, similarity_index_graded_ERDs\n"],"metadata":{"id":"ZoT-Ris4Iuab","executionInfo":{"status":"ok","timestamp":1733424802672,"user_tz":300,"elapsed":180,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def compute_predicted_student_grades(corpus_tfidf_graded_ERDs, corpus_tfidf_ungraded_ERDs, similarity_index_graded_ERDs, list_of_graded_ERDs_keys, list_of_ungraded_ERDs_keys, graded_ERDs_dict, question_number, k_value):\n","\n","  similarities = []\n","\n","   # Iterate through ungraded submissions, for each UNGRADED submission, find similarity between ALL the other GRADED submission\n","  for i, tfidf_ungraded in enumerate(corpus_tfidf_ungraded_ERDs):\n","    # Get the similarity of the current (ith) ungraded submission to all graded submissions\n","    sims = similarity_index_graded_ERDs[tfidf_ungraded]\n","\n","    # Store the similarity vector for the current chapter\n","    similarities.append(sims)\n","\n","  k = k_value\n","\n","  list_of_k_closest_submission_indices = []\n","\n","  # now, I have a list of lists, where the overall list is length 30 for the ungraded submissions, the inner lists are length of 101, so it represents each ungraded submission and its similarity between all 101 graded submissions\n","  for i, sims in enumerate(similarities):\n","    top_k_indices = sorted(range(len(sims)), key=lambda x: sims[x], reverse=True)[:k]\n","    list_of_k_closest_submission_indices.append(top_k_indices)\n","\n","\n","  final_grades_dict = {}\n","\n","  for i, top_k_indices in enumerate(list_of_k_closest_submission_indices):\n","    sum_of_grades = 0\n","    for index in top_k_indices:\n","      graded_erd_number = list_of_graded_ERDs_keys[index]\n","      both_fetched_grade = graded_ERDs_dict[graded_erd_number]\n","      fetched_grade = 0\n","      if (question_number == 1):\n","        fetched_grade = both_fetched_grade[0]\n","      else:\n","        fetched_grade = both_fetched_grade[1]\n","      sum_of_grades += fetched_grade\n","\n","    ungraded_erd_number = list_of_ungraded_ERDs_keys[i]\n","    average_grade = sum_of_grades / k\n","    final_grades_dict[ungraded_erd_number] = average_grade\n","\n","  return final_grades_dict"],"metadata":{"id":"edEEfE3jPw5J","executionInfo":{"status":"ok","timestamp":1733424804735,"user_tz":300,"elapsed":224,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def export_predictions_to_csv(final_grades_dict_question1, final_grades_dict_question2):\n","\n","  # Get sorted ERD numbers (keys) from the dictionaries\n","  erd_numbers = sorted(final_graded_dict_question1.keys())\n","\n","  predictions = []\n","\n","  # Loop through the sorted ERD numbers and fetch the grades\n","  for erd in erd_numbers:\n","\n","    dataset1_grade = final_graded_dict_question1.get(erd)\n","    dataset2_grade = final_graded_dict_question2.get(erd)\n","    predictions.append([erd, round(dataset1_grade, 2), round(dataset2_grade, 2)])\n","\n","  # Write the predictions to a CSV file\n","  with open('/content/drive/MyDrive/cs478ModelTraining/Collection 3/stage2_grading_method1.csv', mode='w', newline='') as file:\n","      writer = csv.writer(file)\n","      writer.writerow(['ERD_No', 'dataset1_grade', 'dataset2_grade'])\n","      writer.writerows(predictions)\n","\n","  print(\"Predictions exported to stage2_grading_method1.csv!\")"],"metadata":{"id":"OckmJci08Qbi","executionInfo":{"status":"ok","timestamp":1733424958123,"user_tz":300,"elapsed":119,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def evaluate_predicted_results(final_grades_dict, graded_ERDs_dict, question_number):\n","\n","  mae_sum = 0\n","  n = 0\n","\n","  for ungraded_key, predicted_grade  in final_grades_dict.items():\n","      if ungraded_key in graded_ERDs_dict:\n","          # Get the actual grade for the ungraded ERD\n","          both_fetched_grade = graded_ERDs_dict[ungraded_key]\n","          actual_grade = 0\n","          if (question_number == 1):\n","            actual_grade = both_fetched_grade[0]\n","          else:\n","            actual_grade = both_fetched_grade[1]\n","\n","          # Calculate absolute error and accumulate\n","          mae_sum += abs(predicted_grade - actual_grade)\n","          n += 1\n","\n","  # Calculate Mean Absolute Error (MAE)\n","  if n > 0:\n","      mae = mae_sum / n\n","      return mae"],"metadata":{"id":"qBL6nVm8Qz0_","executionInfo":{"status":"ok","timestamp":1733424959843,"user_tz":300,"elapsed":150,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def get_graded_dict(question_number):\n","  graded_ERDS_dict, question1_list_of_files, question2_list_of_files = getERDGradesAndListOfSubmissionFiles()\n","\n","  final_erd_dict = {}\n","  if (question_number == 1):\n","    final_erd_dict = preprocess_all_student_submissions_per_question(1, question1_list_of_files, question2_list_of_files)\n","  else:\n","    final_erd_dict = preprocess_all_student_submissions_per_question(2, question1_list_of_files, question2_list_of_files)\n","\n","  graded_erd_dict = {}\n","  ungraded_erd_dict = {}\n","\n","  for key in final_erd_dict:\n","    if key in graded_ERDS_dict:\n","      graded_erd_dict[key] = final_erd_dict[key]\n","    else:\n","      ungraded_erd_dict[key] = final_erd_dict[key]\n","\n","  return graded_erd_dict, ungraded_erd_dict, graded_ERDS_dict\n","\n"],"metadata":{"id":"ZQtMg3u1ThHO","executionInfo":{"status":"ok","timestamp":1733424960715,"user_tz":300,"elapsed":124,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def predict_student_grades(question_number, k_value):\n","\n","  if (question_number != 1 and question_number != 2):\n","    print(\"Invalid question number\")\n","    return\n","\n","  # THIS LINE IS FOR GRADESCOPE SUBMISSION\n","  graded_erd_dict, ungraded_erd_dict, graded_ERDS_dict = get_graded_dict(question_number)\n","\n","  list_of_graded_ERDs_keys = list(graded_erd_dict.keys())\n","  list_of_ungraded_ERDs_keys = list(ungraded_erd_dict.keys())\n","\n","  corpus_tfidf_graded_ERDs, corpus_tfidf_ungraded_ERDs, similarity_index_graded_ERDs = build_tf_idf_vectors(graded_erd_dict, ungraded_erd_dict)\n","\n","  final_grades_dict = compute_predicted_student_grades(corpus_tfidf_graded_ERDs, corpus_tfidf_ungraded_ERDs, similarity_index_graded_ERDs, list_of_graded_ERDs_keys, list_of_ungraded_ERDs_keys, graded_ERDS_dict, question_number, k_value)\n","\n","  # THIS LINE IS FOR GRADESCOPE SUBMISSION\n","  return final_grades_dict"],"metadata":{"id":"b10myOn_2FL6","executionInfo":{"status":"ok","timestamp":1733425731423,"user_tz":300,"elapsed":144,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["final_graded_dict_question1 = predict_student_grades(1, 12)\n","final_graded_dict_question2 = predict_student_grades(2, 12)\n","export_predictions_to_csv(final_graded_dict_question1, final_graded_dict_question2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCHgdsF190HX","executionInfo":{"status":"ok","timestamp":1733425736413,"user_tz":300,"elapsed":3599,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"ed8051f3-08fa-4c5e-a482-d2c97691be8f"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions exported to stage2_grading_method1.csv!\n"]}]},{"cell_type":"markdown","source":["# YOU HAVE TO RUN THE BELOW CELL FOR METHOD 2 and 3!!!"],"metadata":{"id":"uZ7d3YGXvprD"}},{"cell_type":"code","source":["# HAVE TO RUN THIS LINE FOR METHOD 2\n","graded_erd_dict_1, ungraded_erd_dict_1, NOT_USED_1 = get_graded_dict(1)\n","graded_erd_dict_2, ungraded_erd_dict_2, NOT_USED_2 = get_graded_dict(2)"],"metadata":{"id":"TGXetsGnYkYR","executionInfo":{"status":"ok","timestamp":1733425112983,"user_tz":300,"elapsed":3077,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["# METHOD 2 CODE"],"metadata":{"id":"YKIKh-FzBZjO"}},{"cell_type":"code","source":["# General-purpose imports\n","import os\n","import pandas as pd\n","import numpy as np\n","from scipy.spatial.distance import cosine  # For cosine similarity\n","\n","# Gensim imports\n","from gensim.models import Doc2Vec  # For document embeddings\n","from gensim.models.doc2vec import TaggedDocument  # For tagging documents\n","\n","# sklearn imports\n","from sklearn.metrics.pairwise import cosine_similarity  # Optional: Batch cosine similarity\n","from sklearn.neighbors import NearestNeighbors  # KNN for embeddings\n","from sklearn.ensemble import RandomForestRegressor  # Random Forest for Method 3\n","from sklearn.preprocessing import StandardScaler  # Optional: Feature scaling\n","\n","# NLP imports (if preprocessing involves tokenization or stemming)\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","\n","# Ensure nltk resources are available\n","nltk.download('punkt')  # Tokenizer data\n","nltk.download('stopwords')  # Stopwords list\n"],"metadata":{"id":"L67oyGT2XYGU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('all')\n"],"metadata":{"id":"YpBC8QmSw27h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')         # For word tokenization\n","nltk.download('stopwords')     # For English stopwords\n","nltk.download('wordnet')       # For lemmatization\n"],"metadata":{"id":"bZMIDp9jwsKx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733423939814,"user_tz":300,"elapsed":16,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"924df75b-8170-4dd6-ac32-e4835bb7c64d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["from gensim.models.doc2vec import TaggedDocument\n","\n","def prepare_documents_for_doc2vec(erd_dict):\n","    return [TaggedDocument(words=words, tags=[str(erd_id)]) for erd_id, words in erd_dict.items()]\n"],"metadata":{"id":"A9cBIaTF6RjV","executionInfo":{"status":"ok","timestamp":1733425112983,"user_tz":300,"elapsed":1,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Doc2Vec\n","\n","def build_doc2vec_model(tagged_documents, vector_size=100, epochs=40):\n","    model = Doc2Vec(vector_size=vector_size, window=5, min_count=1, workers=4, epochs=epochs)\n","    model.build_vocab(tagged_documents)\n","    model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.epochs)\n","    return model"],"metadata":{"id":"N0nOpKpH6Rly","executionInfo":{"status":"ok","timestamp":1733425113167,"user_tz":300,"elapsed":1,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def compute_doc2vec_embeddings(model, erd_dict):\n","    return {erd_id: model.infer_vector(words) for erd_id, words in erd_dict.items()}\n"],"metadata":{"id":"SIfZsuLn6Rn5","executionInfo":{"status":"ok","timestamp":1733425113589,"user_tz":300,"elapsed":1,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["def predict_grades_using_embeddings(graded_embeddings, ungraded_embeddings, graded_ERDs_dict, k, dataset_number):\n","    final_grades_dict = {}\n","\n","    for ungraded_id, ungraded_vector in ungraded_embeddings.items():\n","        # Calculate similarity (using cosine distance) between this ungraded ERD and all graded ERDs\n","        similarities = [\n","            (graded_id, 1 - cosine(ungraded_vector, graded_vector))\n","            for graded_id, graded_vector in graded_embeddings.items()\n","        ]\n","\n","        # Sort by similarity and get top k neighbors\n","        top_k_neighbors = sorted(similarities, key=lambda x: x[1], reverse=True)[:k]\n","\n","        # Average the grades of the top k most similar graded ERDs, using the specified dataset grade\n","        avg_grade = sum(graded_ERDs_dict[neighbor_id][dataset_number - 1] for neighbor_id, _ in top_k_neighbors) / k\n","        final_grades_dict[ungraded_id] = avg_grade\n","\n","    return final_grades_dict\n"],"metadata":{"id":"dDckNhO16Rp9","executionInfo":{"status":"ok","timestamp":1733425114250,"user_tz":300,"elapsed":190,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["def approach2_grade_prediction(graded_erd_dict, ungraded_erd_dict, graded_ERDs_dict, k_value, dataset_number):\n","    # Prepare documents for Doc2Vec\n","    graded_docs = prepare_documents_for_doc2vec(graded_erd_dict)\n","    ungraded_docs = prepare_documents_for_doc2vec(ungraded_erd_dict)\n","    all_docs = graded_docs + ungraded_docs\n","\n","    # Build Doc2Vec model and infer embeddings\n","    doc2vec_model = build_doc2vec_model(all_docs)\n","    graded_embeddings = compute_doc2vec_embeddings(doc2vec_model, graded_erd_dict)\n","    ungraded_embeddings = compute_doc2vec_embeddings(doc2vec_model, ungraded_erd_dict)\n","\n","    # Predict grades for the specified dataset\n","    return predict_grades_using_embeddings(graded_embeddings, ungraded_embeddings, graded_ERDs_dict, k_value, dataset_number)\n"],"metadata":{"id":"wxO6MyLm4iag","executionInfo":{"status":"ok","timestamp":1733425115074,"user_tz":300,"elapsed":1,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# Get graded ERD dictionary and list of files\n","graded_ERDs_dict, question1_list_of_files, question2_list_of_files = getERDGradesAndListOfSubmissionFiles()\n","\n","# Specify k value for KNN\n","k_value = 12\n","\n","# Run predictions for Dataset 1 grade (dataset_number=1)\n","final_grades_dict_dataset1 = approach2_grade_prediction(graded_erd_dict_1, ungraded_erd_dict_1, graded_ERDs_dict, k_value, dataset_number=1)\n","print(\"Predicted grades for ungraded ERDs (Dataset 1):\")\n","print(final_grades_dict_dataset1)\n","\n","# Run predictions for Dataset 2 grade (dataset_number=2)\n","final_grades_dict_dataset2 = approach2_grade_prediction(graded_erd_dict_2, ungraded_erd_dict_2, graded_ERDs_dict, k_value, dataset_number=2)\n","print(\"Predicted grades for ungraded ERDs (Dataset 2):\")\n","print(final_grades_dict_dataset2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_rRwqA9wOzX","executionInfo":{"status":"ok","timestamp":1733425118288,"user_tz":300,"elapsed":2231,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"73807ca8-6ae8-4e25-cb10-e9d3cac5ce18"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted grades for ungraded ERDs (Dataset 1):\n","{128: 80.33416666666668, 114: 81.22249999999998, 129: 80.66749999999999, 115: 80.33416666666665, 116: 83.77750000000002, 117: 80.445, 107: 77.88916666666667, 106: 79.33333333333333, 105: 78.44500000000001, 112: 76.66666666666667, 104: 80.0, 111: 78.55583333333333, 110: 84.89, 135: 79.1125, 108: 79.66749999999998, 109: 81.00083333333333, 134: 76.77833333333332, 121: 78.00000000000001, 136: 76.88833333333334, 122: 79.66666666666667, 123: 78.33416666666668, 127: 76.33333333333333, 132: 79.55583333333333, 133: 79.00083333333332, 130: 75.55583333333333, 131: 80.00083333333332, 125: 74.44416666666666, 119: 81.55583333333334, 118: 79.445, 124: 75.11166666666668}\n","Predicted grades for ungraded ERDs (Dataset 2):\n","{128: 86.66666666666667, 114: 86.33333333333333, 116: 92.33333333333333, 115: 93.0, 129: 84.33333333333333, 117: 91.0, 107: 89.0, 110: 91.0, 111: 94.66666666666667, 105: 85.66666666666667, 104: 92.0, 106: 88.66666666666667, 112: 92.33333333333333, 135: 87.66666666666667, 109: 83.33333333333333, 108: 92.0, 134: 87.66666666666667, 121: 90.33333333333333, 122: 89.0, 136: 94.33333333333333, 132: 88.0, 123: 88.66666666666667, 133: 92.0, 127: 90.66666666666667, 119: 92.33333333333333, 124: 88.0, 130: 88.33333333333333, 125: 83.66666666666667, 118: 88.0, 131: 89.0}\n"]}]},{"cell_type":"code","source":["def export_predictions_to_csv_method2(final_grades_dict_dataset1, final_grades_dict_dataset2, filename=\"gradescope_method2_doc2vec.csv\"):\n","    # Get sorted ERD numbers (keys) from the dictionaries to ensure consistent order\n","    erd_numbers = sorted(final_grades_dict_dataset1.keys())\n","\n","    predictions = []\n","\n","    # Loop through the sorted ERD numbers and fetch grades for both datasets\n","    for erd in erd_numbers:\n","        dataset1_grade = final_grades_dict_dataset1.get(erd, None)\n","        dataset2_grade = final_grades_dict_dataset2.get(erd, None)\n","        predictions.append([erd, round(dataset1_grade, 2), round(dataset2_grade, 2)])\n","\n","    # Write the predictions to the specified CSV file\n","    with open(f'/content/drive/MyDrive/cs478ModelTraining/Collection 3/{filename}', mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['ERD_No', 'dataset1_grade', 'dataset2_grade'])\n","        writer.writerows(predictions)\n","\n","    print(f\"Predictions exported to {filename}.\")"],"metadata":{"id":"F7G9UjmSwO3J","executionInfo":{"status":"ok","timestamp":1733425119611,"user_tz":300,"elapsed":139,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# Generate predictions for Dataset 1 and Dataset 2\n","final_grades_dict_dataset1 = approach2_grade_prediction(graded_erd_dict_1, ungraded_erd_dict_1, graded_ERDs_dict, k_value, dataset_number=1)\n","final_grades_dict_dataset2 = approach2_grade_prediction(graded_erd_dict_2, ungraded_erd_dict_2, graded_ERDs_dict, k_value, dataset_number=2)\n","\n","# Export predictions to CSV with the file name \"gradescope_method2_doc2vec.csv\"\n","export_predictions_to_csv_method2(final_grades_dict_dataset1, final_grades_dict_dataset2)\n"],"metadata":{"id":"xm-mwySb0K7H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733425125533,"user_tz":300,"elapsed":2199,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"483203f4-9753-44eb-c7f5-306fae6f207e"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions exported to gradescope_method2_doc2vec.csv.\n"]}]},{"cell_type":"code","source":["########################################################################################## SBERT #############################################################################"],"metadata":{"id":"9iofFzcEQqtG","executionInfo":{"status":"ok","timestamp":1733425132700,"user_tz":300,"elapsed":160,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["pip install -U sentence-transformers\n"],"metadata":{"id":"Ibplsb6lQqpc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733425138195,"user_tz":300,"elapsed":4556,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"5d649e95-9ee0-46cf-833d-e6f4b385f8de"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n","Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence-transformers\n","  Attempting uninstall: sentence-transformers\n","    Found existing installation: sentence-transformers 3.2.1\n","    Uninstalling sentence-transformers-3.2.1:\n","      Successfully uninstalled sentence-transformers-3.2.1\n","Successfully installed sentence-transformers-3.3.1\n"]}]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer\n","\n","# Load a pre-trained S-BERT model\n","sbert_model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n","\n","\n","# Convert ERDs to S-BERT embeddings\n","def get_sbert_embeddings(erd_dict):\n","    embeddings = {}\n","    for erd_id, tokens in erd_dict.items():\n","        text = ' '.join(tokens)  # Combine tokens into a single string\n","        embeddings[erd_id] = sbert_model.encode(text)\n","    return embeddings\n"],"metadata":{"id":"1v75I_gbQqjI","executionInfo":{"status":"ok","timestamp":1733425783203,"user_tz":300,"elapsed":1003,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# Generate embeddings for graded and ungraded ERDs\n","graded_embeddings_1 = get_sbert_embeddings(graded_erd_dict_1)\n","ungraded_embeddings_1 = get_sbert_embeddings(ungraded_erd_dict_1)\n","graded_embeddings_2 = get_sbert_embeddings(graded_erd_dict_2)\n","ungraded_embeddings_2 = get_sbert_embeddings(ungraded_erd_dict_2)\n"],"metadata":{"id":"s6HLytGzQyWy","executionInfo":{"status":"ok","timestamp":1733425273816,"user_tz":300,"elapsed":82959,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import NearestNeighbors\n","import numpy as np\n","\n","def knn_grade_prediction(graded_embeddings, ungraded_embeddings, graded_ERDs_dict, k, dataset_number):\n","    # Convert embeddings to a matrix format for KNN\n","    graded_ids = list(graded_embeddings.keys())\n","    graded_matrix = np.array([graded_embeddings[erd_id] for erd_id in graded_ids])\n","    ungraded_ids = list(ungraded_embeddings.keys())\n","    ungraded_matrix = np.array([ungraded_embeddings[erd_id] for erd_id in ungraded_ids])\n","\n","    # Set up KNN\n","    knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n","    knn.fit(graded_matrix)\n","\n","    final_grades_dict = {}\n","\n","    # Find k nearest neighbors and predict grades for each ungraded ERD\n","    for i, ungraded_vector in enumerate(ungraded_matrix):\n","        distances, indices = knn.kneighbors([ungraded_vector])\n","        neighbor_ids = [graded_ids[idx] for idx in indices[0]]\n","\n","        # Calculate average grade for the k nearest neighbors\n","        avg_grade = np.mean([graded_ERDs_dict[neighbor_id][dataset_number - 1] for neighbor_id in neighbor_ids])\n","        final_grades_dict[ungraded_ids[i]] = avg_grade\n","\n","    return final_grades_dict\n"],"metadata":{"id":"pcxcMlcmQ0AU","executionInfo":{"status":"ok","timestamp":1733425273816,"user_tz":300,"elapsed":32,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["def export_predictions_to_csv_sbert(final_grades_dict_dataset1, final_grades_dict_dataset2, filename=\"gradescope_method2_sbert.csv\"):\n","    # Get sorted ERD numbers (keys) from the dictionaries to ensure consistent order\n","    erd_numbers = sorted(final_grades_dict_dataset1.keys())\n","\n","    predictions = []\n","\n","    # Loop through the sorted ERD numbers and fetch grades for both datasets\n","    for erd in erd_numbers:\n","        dataset1_grade = final_grades_dict_dataset1.get(erd, None)\n","        dataset2_grade = final_grades_dict_dataset2.get(erd, None)\n","        predictions.append([erd, round(dataset1_grade, 2), round(dataset2_grade, 2)])\n","\n","    # Write the predictions to the specified CSV file\n","    with open(f'/content/drive/MyDrive/cs478ModelTraining/Collection 3/{filename}', mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['ERD_No', 'dataset1_grade', 'dataset2_grade'])\n","        writer.writerows(predictions)\n","\n","    print(f\"Predictions exported to {filename}.\")"],"metadata":{"id":"gLLzpVS4tijb","executionInfo":{"status":"ok","timestamp":1733425273821,"user_tz":300,"elapsed":31,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# Predict grades for Dataset 1\n","final_grades_dict_dataset1 = knn_grade_prediction(\n","    graded_embeddings_1, ungraded_embeddings_1, graded_ERDs_dict, k=12, dataset_number=1\n",")\n","print(\"Predicted grades for ungraded ERDs (Dataset 1):\")\n","print(final_grades_dict_dataset1)\n","\n","# Predict grades for Dataset 2\n","final_grades_dict_dataset2 = knn_grade_prediction(\n","    graded_embeddings_2, ungraded_embeddings_2, graded_ERDs_dict, k=12, dataset_number=2\n",")\n","print(\"Predicted grades for ungraded ERDs (Dataset 2):\")\n","print(final_grades_dict_dataset2)\n","\n","# Export predictions to CSV with the file name \"gradescope_method2_sbert.csv\"\n","export_predictions_to_csv_sbert(final_grades_dict_dataset1, final_grades_dict_dataset2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zp6xZLi3Q3ke","executionInfo":{"status":"ok","timestamp":1733425274401,"user_tz":300,"elapsed":606,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"bb3258e3-09cc-4efc-e727-77fe1abd3fc8"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted grades for ungraded ERDs (Dataset 1):\n","{128: 75.00083333333333, 114: 81.44583333333333, 129: 75.99916666666667, 115: 76.2225, 116: 74.66583333333334, 117: 78.22166666666668, 107: 79.55666666666667, 106: 79.44500000000001, 105: 75.33416666666668, 112: 78.55583333333333, 104: 80.66749999999998, 111: 81.44500000000001, 110: 79.77916666666667, 135: 81.89, 108: 81.5575, 109: 83.22333333333333, 134: 74.88833333333334, 121: 78.44416666666667, 136: 75.88916666666667, 122: 77.3325, 123: 80.11083333333333, 127: 75.6675, 132: 78.0, 133: 78.66833333333334, 130: 77.44500000000001, 131: 74.44499999999998, 125: 74.88916666666667, 119: 81.00166666666667, 118: 75.00000000000001, 124: 75.44500000000001}\n","Predicted grades for ungraded ERDs (Dataset 2):\n","{128: 87.33333333333333, 114: 88.33333333333333, 116: 91.33333333333333, 115: 91.66666666666667, 129: 84.66666666666667, 117: 90.66666666666667, 107: 90.66666666666667, 110: 89.66666666666667, 111: 92.33333333333333, 105: 88.66666666666667, 104: 87.0, 106: 91.0, 112: 91.33333333333333, 135: 88.33333333333333, 109: 89.33333333333333, 108: 91.66666666666667, 134: 91.0, 121: 87.33333333333333, 122: 92.33333333333333, 136: 90.0, 132: 88.0, 123: 89.33333333333333, 133: 91.33333333333333, 127: 86.66666666666667, 119: 89.0, 124: 91.0, 130: 90.0, 125: 90.33333333333333, 118: 84.66666666666667, 131: 90.66666666666667}\n","Predictions exported to gradescope_method2_sbert.csv.\n"]}]},{"cell_type":"markdown","source":["# METHOD 3 CODE"],"metadata":{"id":"Sv0RZrO1BcE3"}},{"cell_type":"code","source":["from sklearn.ensemble import VotingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from sklearn.model_selection import cross_val_score\n"],"metadata":{"id":"JeMR5UQndXUW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733425432883,"user_tz":300,"elapsed":1836,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"c2f7bc47-e7b5-4470-a3cb-b5762b2545b3"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def extract_features(erd_dict):\n","    features = {}\n","    for erd_id, tokens in erd_dict.items():\n","        num_entities = sum(1 for token in tokens if \"entity\" in token)\n","        num_relationships = sum(1 for token in tokens if \"rel\" in token)\n","        num_attributes = sum(1 for token in tokens if \"attr\" in token)\n","        total_tokens = len(tokens)\n","\n","        # Additional features\n","        avg_word_length = np.mean([len(token) for token in tokens]) if tokens else 0\n","        std_word_length = np.std([len(token) for token in tokens]) if tokens else 0\n","        unique_tokens = len(set(tokens))\n","        attr_entity_ratio = num_attributes / num_entities if num_entities > 0 else 0\n","        rel_entity_ratio = num_relationships / num_entities if num_entities > 0 else 0\n","        entity_token_ratio = num_entities / total_tokens if total_tokens > 0 else 0\n","        rel_token_ratio = num_relationships / total_tokens if total_tokens > 0 else 0\n","        attr_token_ratio = num_attributes / total_tokens if total_tokens > 0 else 0\n","\n","        features[erd_id] = [\n","            num_entities, num_relationships, num_attributes, total_tokens,\n","            avg_word_length, std_word_length, unique_tokens, attr_entity_ratio,\n","            rel_entity_ratio, entity_token_ratio, rel_token_ratio, attr_token_ratio\n","        ]\n","\n","    return features\n"],"metadata":{"id":"HBpstm0jBdKk","executionInfo":{"status":"ok","timestamp":1733425432883,"user_tz":300,"elapsed":1,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","def random_forest_grade_prediction_with_tuning(graded_features, graded_ERDs_dict, ungraded_features, dataset_number):\n","    from sklearn.ensemble import RandomForestRegressor\n","    from sklearn.model_selection import GridSearchCV\n","\n","    # Prepare training data\n","    X_train, y_train = prepare_data_for_dataset(graded_features, graded_ERDs_dict, dataset_number)\n","\n","    # Define the Random Forest model\n","    rf = RandomForestRegressor(random_state=42)\n","\n","    # Define the hyperparameter grid\n","    param_grid = {\n","        'n_estimators': [100, 200, 300],\n","        'max_depth': [None, 10, 20, 30],\n","        'min_samples_split': [2, 5, 10],\n","        'min_samples_leaf': [1, 2, 4]\n","    }\n","\n","    # Set up GridSearchCV\n","    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=3, n_jobs=-1)\n","\n","    # Fit the GridSearchCV\n","    grid_search.fit(X_train, y_train)\n","\n","    # Get the best model\n","    best_rf_model = grid_search.best_estimator_\n","    print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n","\n","    # Prepare testing data\n","    X_test = [features for erd_id, features in ungraded_features.items()]\n","\n","    # Predict grades for the ungraded ERDs\n","    predictions = best_rf_model.predict(X_test)\n","\n","    # Map predictions to ERD IDs\n","    ungraded_erd_ids = list(ungraded_features.keys())\n","    final_grades_dict = {erd_id: pred for erd_id, pred in zip(ungraded_erd_ids, predictions)}\n","\n","    return final_grades_dict\n"],"metadata":{"id":"zHWlr9JXaCbT","executionInfo":{"status":"ok","timestamp":1733425432883,"user_tz":300,"elapsed":1,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# Prepare training data for Dataset 1 or Dataset 2\n","def prepare_data_for_dataset(graded_features, graded_ERDs_dict, dataset_number):\n","    X_train = []\n","    y_train = []\n","    for erd_id, features in graded_features.items():\n","        X_train.append(features)\n","        y_train.append(graded_ERDs_dict[erd_id][dataset_number - 1])  # Use dataset1 or dataset2 grade\n","\n","    return X_train, y_train\n"],"metadata":{"id":"XgpccnphPMbW","executionInfo":{"status":"ok","timestamp":1733425433717,"user_tz":300,"elapsed":149,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["def export_predictions_to_csv_method3(final_grades_dict_dataset1, final_grades_dict_dataset2, filename=\"stage_2_final_method3.csv\"):\n","    # Get sorted ERD numbers (keys) from the dictionaries to ensure consistent order\n","    erd_numbers = sorted(final_grades_dict_dataset1.keys())\n","\n","    predictions = []\n","\n","    # Loop through the sorted ERD numbers and fetch grades for both datasets\n","    for erd in erd_numbers:\n","      dataset1_grade = final_grades_dict_dataset1.get(erd, None)\n","      dataset2_grade = final_grades_dict_dataset2.get(erd, None)\n","      predictions.append([erd, round(dataset1_grade, 2), round(dataset2_grade, 2)])\n","\n","    # Write the predictions to the specified CSV file\n","    with open(f'/content/drive/MyDrive/cs478ModelTraining/Collection 3/{filename}', mode='w', newline='') as file:\n","        writer = csv.writer(file)\n","        writer.writerow(['ERD_No', 'dataset1_grade', 'dataset2_grade'])\n","        writer.writerows(predictions)\n","\n","    print(f\"Predictions exported to {filename}.\")"],"metadata":{"id":"-UE9OQVieZq_","executionInfo":{"status":"ok","timestamp":1733425815295,"user_tz":300,"elapsed":181,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["# Predict grades for Dataset 1\n","\n","graded_features_1 = extract_features(graded_erd_dict_1)\n","ungraded_features_1 = extract_features(ungraded_erd_dict_1)\n","graded_features_2 = extract_features(graded_erd_dict_2)\n","ungraded_features_2 = extract_features(ungraded_erd_dict_2)\n","\n","graded_ERDs_dict, question1_list_of_files, question2_list_of_files = getERDGradesAndListOfSubmissionFiles()\n","\n","\n","final_grades_dict_dataset1 = random_forest_grade_prediction_with_tuning(graded_features_1, graded_ERDs_dict, ungraded_features_1, dataset_number=1)\n","print(\"Predicted grades for ungraded ERDs (Dataset 1):\")\n","print(final_grades_dict_dataset1)\n","\n","# Predict grades for Dataset 2\n","final_grades_dict_dataset2 = random_forest_grade_prediction_with_tuning(graded_features_2, graded_ERDs_dict, ungraded_features_2, dataset_number=2)\n","print(\"Predicted grades for ungraded ERDs (Dataset 2):\")\n","print(final_grades_dict_dataset2)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miAHJQ6WPMiV","executionInfo":{"status":"ok","timestamp":1733426046044,"user_tz":300,"elapsed":213978,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"ea4f52af-37f0-4e92-d8f6-995b0039de6a"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n","Predicted grades for ungraded ERDs (Dataset 1):\n","{128: 75.60318173985057, 114: 79.27530706242831, 129: 78.2060468931994, 115: 80.94750773462101, 116: 74.7673011225349, 117: 78.98403318653024, 107: 79.93769487530449, 106: 77.75901288870176, 105: 75.58885605713732, 112: 94.38928991429864, 104: 90.82887060397938, 111: 80.36025173890384, 110: 75.54120835035336, 135: 81.72443420847681, 108: 80.68954301485556, 109: 77.27353593610096, 134: 75.77981632663635, 121: 81.83071987549482, 136: 72.9148086687849, 122: 79.93807741462247, 123: 74.59462326368079, 127: 71.36029255217007, 132: 79.35104706682212, 133: 86.4509236367745, 130: 75.5680986562675, 131: 76.90046928203057, 125: 76.45053280397163, 119: 79.15156688089688, 118: 73.62552731117742, 124: 76.1301119952433}\n","Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n","Predicted grades for ungraded ERDs (Dataset 2):\n","{128: 85.3366745646751, 114: 92.74155265059439, 116: 91.4920406242321, 115: 90.8251325919809, 129: 90.7254264492082, 117: 88.48495633353153, 107: 91.24922887654198, 110: 93.69979612389669, 111: 90.88260897258252, 105: 88.48495633353153, 104: 88.9849620150039, 106: 89.61314098818275, 112: 91.19605181855178, 135: 92.02572767228192, 109: 88.48495633353153, 108: 91.95659877644027, 134: 87.5509534505153, 121: 87.86207549175069, 122: 92.00418170043687, 136: 93.27579421341183, 132: 92.13577742020628, 123: 88.48495633353153, 133: 91.73782769082764, 127: 89.61314098818275, 119: 92.48752755264495, 124: 90.25807020012444, 130: 91.54426239761179, 125: 87.29561803049815, 118: 85.63688159720154, 131: 88.6200005606135}\n"]}]},{"cell_type":"code","source":["# Export predictions to CSV\n","export_predictions_to_csv_method3(final_grades_dict_dataset1, final_grades_dict_dataset2, filename=\"stage_2_final_method3.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HiEkKX97OwqV","executionInfo":{"status":"ok","timestamp":1733426046045,"user_tz":300,"elapsed":19,"user":{"displayName":"Tanay Athreya","userId":"11076033903721853164"}},"outputId":"5eb2407a-55ad-4137-ef63-68ab8aa759a2"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions exported to stage_2_final_method3.csv.\n"]}]}]}